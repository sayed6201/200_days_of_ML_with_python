{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Test and Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = iris.drop('species',axis=1)\n",
    "y = iris['species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', lm.coef_)\n",
    "\n",
    "predictions = lm.predict( X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Rregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate these metrics by hand!\n",
    "from sklearn import metrics\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "\n",
    "# Residuals\n",
    "sns.distplot((y_test-predictions),bins=50);\n",
    "\n",
    "#coeeficcient check\n",
    "coeffecients = pd.DataFrame(lm.coef_,X.columns) #  pd.DataFrame(lm.coef_, X.columns, columns=['Coefficient'],)\n",
    "\n",
    "coeffecients.columns = ['Coeffecient']\n",
    "coeffecients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine : Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train,y_train)\n",
    "predictions = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_reg = LogisticRegression()\n",
    "\n",
    "logistic_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logistic_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn_model.fit(X_train,y_train)\n",
    "pred_y = knn_model.predict(X=X_test)\n",
    "\n",
    "\n",
    "#improving k value\n",
    "error_rate = []\n",
    "\n",
    "for i in range(1,40):\n",
    "    knn_model_i = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn_model_i.fit(X_train,y_train)\n",
    "    y_pred_i = knn_model_i.predict(X=X_test)\n",
    "    error_rate.append(np.mean(y_pred_i != y_test))\n",
    "    print('printing',error_rate[i-1])\n",
    "    \n",
    "#plotting K value with lesser error rate    \n",
    "plt.plot(range(1,40),error_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decisionTree = DecisionTreeClassifier()\n",
    "\n",
    "decisionTree.fit(X=X_train, y= y_train)\n",
    "\n",
    "y_pred = decisionTree.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomForestClassifier = RandomForestClassifier(n_estimators= 500)\n",
    "\n",
    "randomForestClassifier.fit(X=X_train, y= y_train)\n",
    "\n",
    "y_pred_ensemble = randomForestClassifier.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperpram tuninig: Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001]} \n",
    "\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation:Cassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
